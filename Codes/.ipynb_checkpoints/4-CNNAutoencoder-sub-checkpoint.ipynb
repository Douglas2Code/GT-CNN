{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports, functions and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN import *\n",
    "from GradCAMUtils import *\n",
    "from Utils_auto import *\n",
    "from Autoencoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Constants\"\"\"\n",
    "# sequence length indicate the maximum length for all of the sequnence 626/798\n",
    "SEQUENCE_LENGTH = 798\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "vocab = {'C': [0,0,1], 'H': [0,1,0], 'E': [1,0,0], '-':[0,0,0]}\n",
    "\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le_fold = preprocessing.LabelEncoder()\n",
    "le_fam = preprocessing.LabelEncoder()\n",
    "\n",
    "# torch.cuda.set_device()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "cuda_gpu = torch.cuda.is_available()   #check if gpu is avaliable\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load dataset and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained final model\n",
    "model = pickle.load(open(\"../PretrainedModels/CNNAttention.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster definition\n",
    "GTA_0 = [\"GT14-A\", \"GT16-A\", \"GT2-A\",\"GT25-A\",\"GT45-A\", \"GT49-A\", \"GT60-A\"]\n",
    "GTA_1 = [\"GT15-A\",\"GT17-A\",\"GT31-A\",\"GT34-A\",\"GT43-A\",\"GT6-A\",\"GT62-A\",\"GT67-A\",\"GT7-A\",\"GT77-A\"]\n",
    "GTB_0 = [\"GT1-B\",\"GT10-B\",\"GT20-B\",\"GT28-B\",\"GT37-B\",\"GT38-B\",\"GT4-B\",\"GT47-B\",\"GT5-B\",\"GT63-B\",\"GT72-B\",\"GT79-B\",\"GT9-B\",\"GT90-B\",\"GT93-B\"]\n",
    "GTB_1 = [\"GT23-B\",\"GT3-B\",\"GT35-B\",\"GT41-B\"]\n",
    "GTB_1 = [\"GT104-B\",\"GT30-B\",\"GT70-B\"]\n",
    "GTC_0 = [\"GT39-C\",\"GT57-C\",\"GT66-C\"]\n",
    "GTC_1 = [\"GT50-C\",\"GT58-C\",\"GT87-C\"]\n",
    "GTC_2 = [\"GT22-C\",\"GT83-C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19912 2490 2490\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"../Datasets/Training_data/gt_training.autoencoder.csv\")\n",
    "\n",
    "df_cluter = df_large.loc[df_large['family'].isin(GTA_0)]\n",
    "\n",
    "train_df, val_df = Train_Test_Val_split(df_cluter, test_size=0.05, shuffle=False)\n",
    "test_df = df_large.loc[df_large.fold==\"A\"].loc[~df_large['family'].isin(GTA_0)]\n",
    "\n",
    "df_gtu = pd.read_csv(\"../Datasets/...\")\n",
    "\n",
    "Train_ds, Train_dl = Dataset_Loader(train_df, le_fam, le_fold, vocab, BATCH_SIZE=20, cuda = cuda_gpu)\n",
    "\n",
    "Val_ds, Val_dl = Dataset_Loader(val_df, le_fam, le_fold, vocab, BATCH_SIZE=20, cuda = cuda_gpu)\n",
    "\n",
    "Test_ds, Test_dl = Dataset_Loader(test_df, le_fam, le_fold, vocab, BATCH_SIZE=20, cuda = cuda_gpu)\n",
    "\n",
    "Val_u_ds, Val_u_dl = Dataset_Loader(df_gtu, le_fam, le_fold, vocab, BATCH_SIZE=20, cuda = cuda_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df.loc[df[\"fold\"]==\"A\"]\n",
    "df_B = df.loc[df[\"fold\"]==\"B\"]\n",
    "df_C = df.loc[df[\"fold\"]==\"C\"]\n",
    "df_Lyso = df.loc[df[\"fold\"]==\"lyso\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "# model_autoencoder = autoencoder(model).cuda()\n",
    "# criterion = nn.MSELoss(reduction=\"sum\")\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_autoencoder.parameters()), lr=1e-5)\n",
    "\n",
    "# model_A = fit_autoencoder(60, model_autoencoder, criterion, optimizer, Train_dl, Val_dl, Val_u_dl, patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load for inference\n",
    "\n",
    "model = pickle.load(open('../PretrainedModels/A_subcluster_0.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rerr(df, le_fam, le_fold, vocab, BATCH_SIZE=1, cuda=cuda_gpu, model, name):\n",
    "    reconstruction_err = []\n",
    "    for i, data in enumerate(Train_dl, 0):\n",
    "        model_A.eval()\n",
    "\n",
    "        xb, yb, p = data\n",
    "        output = model(xb)\n",
    "        xb = xb.float()\n",
    "        loss = criterion(output, xb)/(p.sum())\n",
    "\n",
    "        reconstruction_err.append([df.iloc[i].family, loss.item()])\n",
    "\n",
    "    return pd.DataFrame(reconstruction_err, columns=[\"fold\", \"Err\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerr_A = get_rerr(df=df_cluter, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model, name)\n",
    "rerr_B = get_rerr(df=df_B, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model, name)\n",
    "rerr_C = get_rerr(df=df_C, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model, name)\n",
    "rerr_lyso = get_rerr(df=df_lyso, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model, name)\n",
    "rerr_gtu = get_rerr(df=df_gtu, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerr_A.to_csv(\"rerr_gta0_training.csv\", index = False)\n",
    "alltest_rerr= pd.concat([rerr_B, rerr_C, reconstruction_err_gtc, rerr_lyso, rerr_gtu], axis=0)\n",
    "alltest_rerr.to_csv(\"rerr_gta0_Alltest.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
