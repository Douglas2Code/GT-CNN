{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports, functions and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN import *\n",
    "from GradCAMUtils import *\n",
    "from Utils_auto import *\n",
    "from Autoencoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Constants\"\"\"\n",
    "# sequence length indicate the maximum length for all of the sequnence 626/798\n",
    "SEQUENCE_LENGTH = 798\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "vocab = {'C': [0,0,1], 'H': [0,1,0], 'E': [1,0,0], '-':[0,0,0]}\n",
    "\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le_fold = preprocessing.LabelEncoder()\n",
    "le_fam = preprocessing.LabelEncoder()\n",
    "\n",
    "# torch.cuda.set_device()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "cuda_gpu = torch.cuda.is_available()   #check if gpu is avaliable\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load dataset and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained final model\n",
    "model = pickle.load(open(\"../PretrainedModels/CNNAttention.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster definition\n",
    "GTA_0 = [\"GT14-A\", \"GT16-A\", \"GT2-A\",\"GT25-A\",\"GT45-A\", \"GT49-A\", \"GT60-A\"]\n",
    "GTA_1 = [\"GT15-A\",\"GT17-A\",\"GT31-A\",\"GT34-A\",\"GT43-A\",\"GT6-A\",\"GT62-A\",\"GT67-A\",\"GT7-A\",\"GT77-A\"]\n",
    "GTB_0 = [\"GT1-B\",\"GT10-B\",\"GT20-B\",\"GT28-B\",\"GT37-B\",\"GT38-B\",\"GT4-B\",\"GT47-B\",\"GT5-B\",\"GT63-B\",\"GT72-B\",\"GT79-B\",\"GT9-B\",\"GT90-B\",\"GT93-B\"]\n",
    "GTB_1 = [\"GT23-B\",\"GT3-B\",\"GT35-B\",\"GT41-B\"]\n",
    "GTB_1 = [\"GT104-B\",\"GT30-B\",\"GT70-B\"]\n",
    "GTC_0 = [\"GT39-C\",\"GT57-C\",\"GT66-C\"]\n",
    "GTC_1 = [\"GT50-C\",\"GT58-C\",\"GT87-C\"]\n",
    "GTC_2 = [\"GT22-C\",\"GT83-C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"../Datasets/Training_data/gt_training.autoencoder.csv\")\n",
    "\n",
    "df_cluter = df.loc[df['family'].isin(GTA_0)]\n",
    "\n",
    "train_df, val_df = train_test_split(df_cluter, test_size=0.05, shuffle=False)\n",
    "test_df = df.loc[df.fold==\"A\"].loc[~df['family'].isin(GTA_0)]\n",
    "\n",
    "df_gtu = pd.read_csv(\"../Datasets/gtu/gtu.processed.csv\")\n",
    "\n",
    "Train_ds, Train_dl = Dataset_Loader(train_df, le_fam, le_fold, vocab, BATCH_SIZE=20, cuda = cuda_gpu)\n",
    "\n",
    "Val_ds, Val_dl = Dataset_Loader(val_df, le_fam, le_fold, vocab, BATCH_SIZE=20, cuda = cuda_gpu)\n",
    "\n",
    "Test_ds, Test_dl = Dataset_Loader(test_df, le_fam, le_fold, vocab, BATCH_SIZE=20, cuda = cuda_gpu)\n",
    "\n",
    "Val_u_ds, Val_u_dl = Dataset_Loader(df_gtu, le_fam, le_fold, vocab, BATCH_SIZE=20, cuda = cuda_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df.loc[df[\"fold\"]==\"A\"]\n",
    "df_B = df.loc[df[\"fold\"]==\"B\"]\n",
    "df_C = df.loc[df[\"fold\"]==\"C\"]\n",
    "df_Lyso = df.loc[df[\"fold\"]==\"lyso\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzl/anaconda3/envs/GT_test/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1 \tTraining Loss :37.706268.\n",
      "Epoch :1 \tVal Loss :32.687192.\n",
      "Epoch :1 \tVal OOD Loss :31.236634.\n",
      "Validation loss decreased (inf --> 32.687192).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training the model\n",
    "model_autoencoder = autoencoder(model).cuda()\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_autoencoder.parameters()), lr=1e-5)\n",
    "\n",
    "model_A = fit_autoencoder(1, model_autoencoder, criterion, optimizer, Train_dl, Val_dl, Val_u_dl, patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load for inference\n",
    "\n",
    "model = pickle.load(open('../PretrainedModels/Autoencoder_gta0.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rerr(df, le_fam, le_fold, vocab, BATCH_SIZE=1, cuda=cuda_gpu, model=model):\n",
    "    reconstruction_err = []\n",
    "    for i, data in enumerate(Train_dl, 0):\n",
    "        model_A.eval()\n",
    "\n",
    "        xb, yb, p = data\n",
    "        output = model(xb)\n",
    "        xb = xb.float()\n",
    "        loss = criterion(output, xb)/(p.sum())\n",
    "\n",
    "        reconstruction_err.append([df.iloc[i].family, loss.item()])\n",
    "\n",
    "    return pd.DataFrame(reconstruction_err, columns=[\"fold\", \"Err\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerr_A = get_rerr(df=df_cluter, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model=model)\n",
    "rerr_B = get_rerr(df=df_B, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model=model)\n",
    "rerr_C = get_rerr(df=df_C, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model=model)\n",
    "rerr_lyso = get_rerr(df=df_Lyso, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model=model)\n",
    "rerr_gtu = get_rerr(df=df_gtu, le_fam=le_fam, le_fold=le_fold, vocab=vocab, BATCH_SIZE=1, cuda=cuda_gpu, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerr_A.to_csv(\"rerr_gta0_training.csv\", index = False)\n",
    "alltest_rerr= pd.concat([rerr_B, rerr_C, reconstruction_err_gtc, rerr_lyso, rerr_gtu], axis=0)\n",
    "alltest_rerr.to_csv(\"rerr_gta0_Alltest.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
